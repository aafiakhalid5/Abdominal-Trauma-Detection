{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":52254,"databundleVersionId":9674523,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:53:02.668641Z","iopub.execute_input":"2025-01-20T11:53:02.669005Z","iopub.status.idle":"2025-01-20T11:53:02.673046Z","shell.execute_reply.started":"2025-01-20T11:53:02.668978Z","shell.execute_reply":"2025-01-20T11:53:02.671992Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         # print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:53:02.678520Z","iopub.execute_input":"2025-01-20T11:53:02.678818Z","iopub.status.idle":"2025-01-20T11:53:02.691398Z","shell.execute_reply.started":"2025-01-20T11:53:02.678796Z","shell.execute_reply":"2025-01-20T11:53:02.690276Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_series_meta = pd.read_csv('/kaggle/input/rsna-2023-abdominal-trauma-detection/train_series_meta.csv')\ntrain_series_meta.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:53:02.695002Z","iopub.execute_input":"2025-01-20T11:53:02.695349Z","iopub.status.idle":"2025-01-20T11:53:02.720518Z","shell.execute_reply.started":"2025-01-20T11:53:02.695322Z","shell.execute_reply":"2025-01-20T11:53:02.719674Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_level_labels_2024 = pd.read_csv('/kaggle/input/rsna-2023-abdominal-trauma-detection/image_level_labels_2024.csv')\nimage_level_labels_2024.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:53:02.721655Z","iopub.execute_input":"2025-01-20T11:53:02.721965Z","iopub.status.idle":"2025-01-20T11:53:02.744016Z","shell.execute_reply.started":"2025-01-20T11:53:02.721927Z","shell.execute_reply":"2025-01-20T11:53:02.743146Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import keras_cv\nimport keras_core as keras\nfrom keras_core import layers\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:53:02.745759Z","iopub.execute_input":"2025-01-20T11:53:02.746065Z","iopub.status.idle":"2025-01-20T11:53:02.750818Z","shell.execute_reply.started":"2025-01-20T11:53:02.746041Z","shell.execute_reply":"2025-01-20T11:53:02.749796Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **EDA**\n\nReference Notebook: https://www.kaggle.com/code/aritrag/eda-train-csv\n\n**Key observations related to the data**:\n* **Healthy columns corelation**: The correlations between different health columns are generally small, indicating that the healthy state of one organ might not be strongly related to the healthy state of other organs.\n* **Injury corelation:** There are some specific correlations between individual injury types, such as the correlation between extravasation_injury and spleen_high. However, the correlation between different organs' injuries is generally low, which might suggest that injuries to different organs occur independently of each other.\n \n* **Relation between class**: bowel_injury and bowel_healthy are complementary. Their probabilities add up to 1.0.\nSimilarly, extravasation_injury and extravasation_healthy are complementary.\n\n* **Simplification**: For the model, only {bowel/extravasation}_injury will be included, and the corresponding healthy status can be calculated using a sigmoid function.\n\n* **Softmax**: {kidney/liver/spleen}_{healthy/low/high} classifications are softmaxed, ensuring their combined probabilities sum up to 1.0 for each organ, simplifying the model while preserving essential information.","metadata":{}},{"cell_type":"markdown","source":"# **Configuration Class**","metadata":{}},{"cell_type":"code","source":"\nclass Config:\n    SEED = 42\n    IMAGE_SIZE = [256, 256]\n    BATCH_SIZE = 64\n    EPOCHS = 10\n    TARGET_COLS  = [\n        \"bowel_injury\", \"extravasation_injury\",\n        \"kidney_healthy\", \"kidney_low\", \"kidney_high\",\n        \"liver_healthy\", \"liver_low\", \"liver_high\",\n        \"spleen_healthy\", \"spleen_low\", \"spleen_high\",\n    ]\n    AUTOTUNE = tf.data.AUTOTUNE\n\nconfig = Config()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:53:02.752190Z","iopub.execute_input":"2025-01-20T11:53:02.752509Z","iopub.status.idle":"2025-01-20T11:53:02.774534Z","shell.execute_reply.started":"2025-01-20T11:53:02.752485Z","shell.execute_reply":"2025-01-20T11:53:02.773436Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Reproductibility ","metadata":{}},{"cell_type":"code","source":"keras.utils.set_random_seed(seed=config.SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:53:02.775468Z","iopub.execute_input":"2025-01-20T11:53:02.775828Z","iopub.status.idle":"2025-01-20T11:53:02.790682Z","shell.execute_reply.started":"2025-01-20T11:53:02.775788Z","shell.execute_reply":"2025-01-20T11:53:02.789737Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data set\n\nThis train.csv file contains details about the dataset, stored in a table-like format. Here's what each column means:abs\n\n**patient_id:** A unique identifier for each patient. This ensures that each patient’s data can be easily tracked.\n\n**series_id**: A unique identifier for each scan (series of images) for a patient. A patient can have multiple scans.\n\n**instance_number**: The specific image number in a scan. Medical scans consist of multiple \"slices,\" and this number helps identify them.\n\n**[bowel/extravasation]_[healthy/injury]:** These columns indicate whether the patient has bowel or extravasation injuries (binary targets: 0 for healthy, 1 for injury).\n\n**[kidney/liver/spleen]_[healthy/low/high]:** These columns specify the injury severity for organs:\n* healthy: No injury\n* low: Mild injury\n* high: Severe injury\n* any_injury: A binary column indicating if the patient has any injury at all (1 for injured, 0 for healthy).","metadata":{}},{"cell_type":"code","source":"BASE_PATH = f\"/kaggle/input/rsna-2023-abdominal-trauma-detection\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:53:02.791619Z","iopub.execute_input":"2025-01-20T11:53:02.791919Z","iopub.status.idle":"2025-01-20T11:53:02.806789Z","shell.execute_reply.started":"2025-01-20T11:53:02.791879Z","shell.execute_reply":"2025-01-20T11:53:02.805763Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train\nimage_level_labels_2024_dataframe = pd.read_csv(f\"{BASE_PATH}/image_level_labels_2024.csv\")\nimage_level_labels_2024_dataframe[\"image_path\"] = f\"{BASE_PATH}/train_images\"\\\n                    + \"/\" + dataframe.patient_id.astype(str)\\\n                    + \"/\" + dataframe.series_id.astype(str)\\\n                    + \"/\" + dataframe.instance_number.astype(str) +\".png\"\nimage_level_labels_2024_dataframe = image_level_labels_2024_dataframe.drop_duplicates()\n\nimage_level_labels_2024_dataframe.head(2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T12:02:15.937955Z","iopub.execute_input":"2025-01-20T12:02:15.938375Z","iopub.status.idle":"2025-01-20T12:02:16.003025Z","shell.execute_reply.started":"2025-01-20T12:02:15.938349Z","shell.execute_reply":"2025-01-20T12:02:16.001933Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset¶\nThe dataset provided in the competition consists of DICOM images. We will not be training on the DICOM images, rather would work on PNG image which are extracted from the DICOM format.\n\n[A helpful resource on the conversion of DICOM to PNG](http://https://www.kaggle.com/code/radek1/how-to-process-dicom-images-to-pngs)","metadata":{}},{"cell_type":"markdown","source":"We split the training dataset into train and validation. This is a common practise in the Machine Learning pipelines. We not only want to train our model, but also want to validate it's training.\n\nA small catch here is that the training and validation data should have an aligned data distribution. Here we handle that by grouping the lables and then splitting the dataset. This ensures an aligned data distribution between the training and the validation splits","metadata":{}},{"cell_type":"code","source":"train_2024_dataframe = pd.read_csv(f\"{BASE_PATH}/train_2024.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T12:02:22.705519Z","iopub.execute_input":"2025-01-20T12:02:22.705923Z","iopub.status.idle":"2025-01-20T12:02:22.722121Z","shell.execute_reply.started":"2025-01-20T12:02:22.705894Z","shell.execute_reply":"2025-01-20T12:02:22.720859Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to handle the split for each group\ndef split_group(group, test_size=0.2):\n    if len(group) == 1:\n        return (group, pd.DataFrame()) if np.random.rand() < test_size else (pd.DataFrame(), group)\n    else:\n        return train_test_split(group, test_size=test_size, random_state=42)\n\n# Initialize the train and validation datasets\ntrain_data = pd.DataFrame()\nval_data = pd.DataFrame()\n\n# Iterate through the groups and split them, handling single-sample groups\nfor _, group in train_2024_dataframe.groupby(config.TARGET_COLS):\n    train_group, val_group = split_group(group)\n    train_data = pd.concat([train_data, train_group], ignore_index=True)\n    val_data = pd.concat([val_data, val_group], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T12:02:23.050657Z","iopub.execute_input":"2025-01-20T12:02:23.051064Z","iopub.status.idle":"2025-01-20T12:02:23.129537Z","shell.execute_reply.started":"2025-01-20T12:02:23.051029Z","shell.execute_reply":"2025-01-20T12:02:23.128456Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.shape, val_data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T12:02:26.253059Z","iopub.execute_input":"2025-01-20T12:02:26.253427Z","iopub.status.idle":"2025-01-20T12:02:26.259966Z","shell.execute_reply.started":"2025-01-20T12:02:26.253374Z","shell.execute_reply":"2025-01-20T12:02:26.258934Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}